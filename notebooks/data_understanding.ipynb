{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/customer_supermarket.csv\", sep=\"\\t\", index_col=0, parse_dates=[\"BasketDate\"], decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can have an idea of data types we are going to use\n",
    "\n",
    "| Attribute       | Type       |\n",
    "|-----------------|------------|\n",
    "| BasketID        | int64      |\n",
    "| BasketDate      | datetime64 |\n",
    "| Sale            | float64    |\n",
    "| CustomerID      | int64      |\n",
    "| CustomerCountry | object     |\n",
    "| ProdID          | object     |\n",
    "| ProdDescr       | object     |\n",
    "| Qta             | int64      |\n",
    "\n",
    "as we can see there are problems in the attribute values, so we have to evaluate what prevents us from getting the desired data types:\n",
    "\n",
    "The execution df['BasketID'].astype(int) tell us that some rows contains literal inside the attribute BasketID, this means the data type cannot be converted to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking NaN values and duplicates\n",
    "\n",
    "It is possible to evaluate the quality of the data from the point of view of the rows, based on two aspects:\n",
    "- missing or partial value (NaN/Null values)\n",
    "- duplicates\n",
    "- duplicates products in the same basket\n",
    "\n",
    "Any duplicates or rows with missing values are temporarily removed from the dataset to allow for better evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicates\n",
    "areduplicates = df.duplicated().any()\n",
    "\n",
    "# duplicates have been removed from the data set\n",
    "df_nodup = df.drop_duplicates()\n",
    "\n",
    "# check if there are missing or incomplete values\n",
    "arenan = df.isnull().values.any()\n",
    "\n",
    "# rows with missing or incomplete values have been removed from the data set\n",
    "df_clean = df_nodup.dropna()\n",
    "\n",
    "print(\"There are duplicates: \", areduplicates, \"Number or rows removed: \", len(df)-len(df_nodup))\n",
    "print(\"There are NaN/Null: \", arenan, \"Number or rows removed: \", len(df_nodup)-len(df_clean))\n",
    "\n",
    "nmb_of_rmv_rows = len(df)-len(df_clean)\n",
    "\n",
    "print(\"Number of rows with apparent problems to solve:\", 100*nmb_of_rmv_rows/len(df), \"%\")\n",
    "\n",
    "\n",
    "df_Sale_Qta_merge = df_clean.groupby(['BasketID','BasketDate','ProdID']).agg({'Qta':np.sum,\n",
    "                                                                         'Sale':np.sum,\n",
    "                                                                         'CustomerID':'min',\n",
    "                                                                         'CustomerCountry':'min',\n",
    "                                                                         'ProdDescr':'min'}).reset_index()\n",
    "\n",
    "df_Sale_Qta_merge.to_csv(\"../dataset/customer_supermarket_sale_qta_merge.csv\", sep=\"\\t\", decimal=\",\")\n",
    "\n",
    "print(f\"Number of duplicates inside baskets {len(df_clean) - len(df_Sale_Qta_merge)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data consistency\n",
    "\n",
    "Here we are verifing that the dataset is consistent:\n",
    "\n",
    "1. Every ProdID must match the same ProdDescr\n",
    "2. Every CustomerID must match the same BasketID in the same BasketDate\n",
    "3. Every CustomerID must match the same CustomerCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inconsistent_set(K,V):\n",
    "    \n",
    "    inconsistentset = list()\n",
    "\n",
    "    for key in tqdm(df_Sale_Qta_merge[K].unique().tolist()):\n",
    "        temp_df = df_Sale_Qta_merge[df_Sale_Qta_merge[K] == key]\n",
    "        valueslist = temp_df[V].tolist()\n",
    "        for value in valueslist:\n",
    "            if(valueslist[0] != value):\n",
    "                inconsistentset.append(key)\n",
    "                break;\n",
    "    return inconsistentset\n",
    "\n",
    "\n",
    "# 1\n",
    "ProdID_ProdDescr_IS = inconsistent_set(\"ProdID\",\"ProdDescr\")\n",
    "            \n",
    "print(\"Number of not consistent ProdDescr:\", len(ProdID_ProdDescr_IS))\n",
    "\n",
    "with open('../dataset/inconsistent_ProdID_ProdDescr.json', 'w') as f:\n",
    "    json.dump(ProdID_ProdDescr_IS, f, sort_keys=True)\n",
    "\n",
    "\n",
    "#2 True == no error\n",
    "temp = df_Sale_Qta_merge.groupby(['BasketID','BasketDate']).CustomerID.nunique().eq(1)\n",
    "print(temp.all())\n",
    "\n",
    "#3 \n",
    "CustomerID_CustomerCountry_IS = inconsistent_set(\"CustomerID\",\"CustomerCountry\")\n",
    "            \n",
    "print(\"Number of not consistent CustomerCountry:\", len(CustomerID_CustomerCountry_IS))\n",
    "\n",
    "\n",
    "with open('../dataset/inconsistent_CustomerID_CustomerCountry.json', 'w') as f:\n",
    "    json.dump(CustomerID_CustomerCountry_IS, f, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting attributes to correct data type\n",
    "\n",
    "Here we are changing the type of attributes. This imply a little cleaning phase over BasketID because there are characters inside the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Sale_Qta_merge['CustomerID'] = pd.to_numeric(df_Sale_Qta_merge.CustomerID)\n",
    "df_Sale_Qta_merge.CustomerID = df_Sale_Qta_merge.CustomerID.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only attribute that still has a wrong datatype is BasketID, we have to remove letters at the beginning of the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex matchin everything except digits\n",
    "regex = \"\\D+\"\n",
    "df_regex = pd.DataFrame(df_Sale_Qta_merge)\n",
    "df_regex['BasketID'] = df_regex['BasketID'].replace(to_replace=r'\\D+', value='', regex=True)\n",
    "df_regex.BasketID = pd.to_numeric(df_regex.BasketID)\n",
    "df_regex.info()\n",
    "df_regex.to_csv(\"../dataset/customer_supermarket_regex.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics and data understanding (maybe Data preparation???)\n",
    "\n",
    "Here are informations about quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of clients: \",len(df_regex['CustomerID'].unique()))\n",
    "print(\"Number of products: \",len(df_regex['ProdID'].unique()))\n",
    "print(\"Number of purchase: \",len(df_regex['BasketID'].unique()))\n",
    "print(\"Distinct values in Customer Country: \\t\", len(df_regex.CustomerCountry.unique()))\n",
    "#print(\"Distinct values in ProdID: \\t\", df_clean.ProdID.unique())\n",
    "#print(\"Distinct values in ProdDescr: \\t\", df_clean.ProdDescr.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have people coming from unspecified countries, a generic \"European Community\", EIRE which stands for Ireland and RSA which stands for Republic of South Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of customers from Unspecified countries: \\t\", (df_clean.CustomerCountry == \"Unspecified\").sum())\n",
    "print(\"Number of customers from generic European Community countries: \\t\", (df_clean.CustomerCountry == \"European Community\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regex.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be absolutely no correlation between the values of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_regex.corr(method=\"pearson\")\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cmap = sns.color_palette(\"Blues\")\n",
    "sns.heatmap(correlations, annot=True, cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = df_regex.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df_regex[['BasketID', 'CustomerID', 'Qta', 'Sale']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_regex.groupby('CustomerCountry').CustomerID.nunique().reset_index()\n",
    "print(type(temp))\n",
    "#temp.plot(kind='bar', title='Size Counts')\n",
    "plt.bar(temp['CustomerCountry'],temp['CustomerID'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot shows irregular Qta and Sale, probably outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qta_std = df_regex['Qta'].std()\n",
    "qta_mean = df_regex['Qta'].mean()\n",
    "\n",
    "sale_std = df_regex['Sale'].std()\n",
    "sale_mean = df_regex['Sale'].mean()\n",
    "\n",
    "print(\"QTA STD: \", qta_std, \" QTA MEAN: \", qta_mean)\n",
    "print(\"SALE STD: \", sale_std, \" SALE MEAN: \", sale_mean)\n",
    "\n",
    "threshold = 15\n",
    "\n",
    "def outliers_zscore(qta,sale):\n",
    "    \n",
    "    qta_z_score = (qta - qta_mean) / qta_std\n",
    "    if(np.abs(qta_z_score) > threshold):\n",
    "        return True\n",
    "    \n",
    "    sale_z_score = (sale - sale_mean) / sale_std\n",
    "    if(np.abs(sale_z_score) > threshold):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "df_regex['Outlier'] = df_regex.apply(lambda x: outliers_zscore(x['Qta'],x['Sale']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df = df_regex[df_regex['Outlier'] == True]\n",
    "notoutliers_df = df_regex[df_regex['Outlier'] == False]\n",
    "\n",
    "plt.scatter(outliers_df['Qta'],outliers_df['Sale'], color='r', marker='*')\n",
    "\n",
    "plt.scatter(notoutliers_df['Qta'],notoutliers_df['Sale'], color='g', marker='*')\n",
    "\n",
    "\n",
    "plt.xlabel('Qta')\n",
    "plt.ylabel('Sale')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CESTINO\n",
    "\n",
    "df_clean.infer_objects().dtypes\n",
    "\n",
    "print(df_clean.convert_dtypes().info())\n",
    "\n",
    "df_clean.describe()\n",
    "\n",
    "df_regex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(df_regex['Qta'], df_regex['Sale'], color='g', marker='*', label='Dinner')\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "temp['Result'] = df_regex['Sale']/df_regex['Qta']\n",
    "\n",
    "qta_mean = df_regex['Qta'].mean()\n",
    "sale_mean = df_regex['Sale'].mean()\n",
    "\n",
    "plt.scatter(df_regex[df_regex['Qta'] < qta_mean+1000]['Qta'], \n",
    "            df_regex[df_regex['Sale'] < sale_mean+1000 ]['Sale'], color='g', marker='*')\n",
    "\n",
    "plt.scatter(df_regex[df_regex['Qta'] > qta_mean+1000]['Qta'], \n",
    "            df_regex[df_regex['Sale'] > sale_mean+1000]['Sale'], color='r', marker='*')\n",
    "\n",
    "plt.xlabel('Qta')\n",
    "plt.ylabel('Sale')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "zscores = scipy.stats.zscore(df_regex)\n",
    "abs_zscores = np.abs(zscore)\n",
    "filtered_outliers = (abs_zscores < 3).all(axis = 1)\n",
    "\n",
    "df_no_outliers = df_regex(filtered_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers.describe\n",
    "df_no_outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
