{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "The following cells will improve the DF, which presents inconsistency, missing values and outliers, thanks to consideration done during the data understanding phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inconsistency resolution\n",
    "df = pd.read_csv(\"../dataset/customer_supermarket_sale_qta_merge.csv\", sep=\"\\t\", index_col=0, parse_dates=[\"BasketDate\"], decimal=\",\")\n",
    "\n",
    "def inconsistency_resolver(path,col1,col2):\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        inconsistent_list = json.load(f)\n",
    "        \n",
    "    df_inconsistent = df[df[col1].isin(inconsistent_list)]\n",
    "\n",
    "    df_grouped = df_inconsistent.groupby([col1,col2]).size().reset_index()\n",
    "    \n",
    "    df_grouped = df_grouped.sort_values(0, ascending=False).drop_duplicates(col1).sort_index()\n",
    "    \n",
    "    mydict = pd.Series(df_grouped[col2].values,index=df_grouped[col1]).to_dict()\n",
    "    \n",
    "    for k,v in mydict.items():\n",
    "        \n",
    "        df.loc[df[col1] == k, col2] = v\n",
    "\n",
    "inconsistency_resolver(\"../dataset/inconsistent_CustomerID_CustomerCountry.json\",\"CustomerID\",\"CustomerCountry\") \n",
    "inconsistency_resolver(\"../dataset/inconsistent_ProdID_ProdDescr.json\",\"ProdID\",\"ProdDescr\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inconsistent_set(K,V):\n",
    "    \n",
    "    inconsistentset = list()\n",
    "\n",
    "    for key in df[K].unique().tolist():\n",
    "        temp_df = df[df[K] == key]\n",
    "        valueslist = temp_df[V].tolist()\n",
    "        for value in valueslist:\n",
    "            if(valueslist[0] != value):\n",
    "                inconsistentset.append(key)\n",
    "                break;\n",
    "    return inconsistentset\n",
    "\n",
    "\n",
    "# 1\n",
    "ProdID_ProdDescr_IS = inconsistent_set(\"ProdID\",\"ProdDescr\")\n",
    "            \n",
    "print(\"Number of not consistent ProdDescr:\", len(ProdID_ProdDescr_IS))\n",
    "\n",
    "#3 \n",
    "CustomerID_CustomerCountry_IS = inconsistent_set(\"CustomerID\",\"CustomerCountry\")\n",
    "            \n",
    "print(\"Number of not consistent CustomerCountry:\", len(CustomerID_CustomerCountry_IS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"CustomerID\"] == \"12394.0\", \"CustomerCountry\"] = \"Belgium\"\n",
    "print(df.loc[df[\"CustomerID\"] == \"12394.0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all we deserialize our dataframe\n",
    "df = pd.read_csv(\"../dataset/customer_supermarket.csv\", sep=\"\\t\", index_col=0, parse_dates=[\"BasketDate\"], decimal=\",\")\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - indicator\n",
    "the total number of items purchased by a customer during the period of\n",
    "observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df.groupby(\"CustomerID\").sum().reset_index()\n",
    "df_i = df_i[[\"CustomerID\", \"Qta\"]]\n",
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!! look at this, it might be an outlier\n",
    "print(df[df.CustomerID == 12346])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iu - indicator\n",
    "the number of distinct items bought by a customer in the period of\n",
    "observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iu = df.groupby('CustomerID')['ProdID'].nunique().reset_index()\n",
    "df_iu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imax - indicator\n",
    "the maximum number of items purchased by a customer during a\n",
    "shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imax = df.groupby([\"CustomerID\", \"BasketID\"]).Qta.sum()\n",
    "df_imax = df_imax.groupby(level=0).head(1).reset_index()\n",
    "\n",
    "#df_imax = df_imax.max(level=0)\n",
    "\n",
    "df_imax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - indicator\n",
    "the Shannon entropy on the purchasing behaviour of the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.groupby([\"CustomerID\", \"BasketID\"]).Qta.sum().reset_index()\n",
    "values = df_temp[\"Qta\"]\n",
    "df_temp['Entropy'] = -(values*np.log(values))\n",
    "df_entropy = df_temp.groupby('CustomerID')['Entropy'].sum().reset_index()\n",
    "# to remove nan values caused by logs\n",
    "df_entropy['Entropy'] = df_entropy['Entropy'].fillna(0)\n",
    "\n",
    "\n",
    "df_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting together all indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_entropy, df_imax.Qta, df_iu.ProdID, df_i.Qta]\n",
    "indicators = pd.concat(frames, join='outer', axis=1)\n",
    "indicators.columns = (\"CustomerID\", \"Entropy\", \"imax\", \"iu\", \"i\")\n",
    "print(indicators.head())\n",
    "\n",
    "indicators.to_csv(\"../dataset/indicators.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales per country\n",
    "(is this even an indicator?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_per_country = df.groupby([\"CustomerCountry\"])[\"Sale\"].sum().reset_index()\n",
    "print(df_sales_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pie plot is horrible because of england, that probably has some outliers\n",
    "#explode=np.zeros(len(df_sales_per_country.CustomerCountry))\n",
    "\n",
    "plt.pie(df_sales_per_country.Sale, labels=df_sales_per_country.CustomerCountry, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most bought items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dropped = [2, 3, 6]\n",
    "df_most_bought = df.groupby([\"ProdID\", \"ProdDescr\"]).sum().reset_index()\n",
    "#df_most_bought = df_most_bought.drop(df_most_bought.columns[cols_dropped], axis=1)\n",
    "df_most_bought = df_most_bought.sort_values(by=\"Qta\", ascending=False)\n",
    "#df_most_bought = df_most_bought.groupby(level=0).head(1).reset_index()\n",
    "df_most_bought \n",
    "\n",
    "#print(df[df.ProdDescr == \"Discount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df_most_bought[:10].Qta, labels=df_most_bought[:10].ProdDescr, autopct='%1.1f%%')\n",
    "plt.savefig(\"../output/most_bought_item_piechart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most bought item per country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_dropped = [3, 4, 7]\n",
    "df_mb_country = df.groupby([\"ProdID\", \"ProdDescr\", \"CustomerCountry\"]).sum().reset_index()\n",
    "df_mb_country = df_mb_country.drop([\"Sale\"], axis = 1)\n",
    "\n",
    "df_mb_country = df_mb_country[df_mb_country.groupby([\"CustomerCountry\"])[\"Qta\"].transform(\"max\") == df_mb_country[\"Qta\"]].reset_index()\n",
    "\n",
    "#df_mb_country = df_mb_country.groupby([\"CustomerCountry\"]).agg({\"Qta\" : \"max\"}).reset_index()\n",
    "#print(df_mb_country.CustomerCountry.unique())\n",
    "\n",
    "\n",
    "print(df_mb_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end datetimes\n",
    "print(df.BasketDate.min(), df.BasketDate.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = df.set_index(\"BasketDate\").copy()\n",
    "weekly = weekly.groupby(pd.Grouper(freq='M'))[\"Qta\"].sum()\n",
    "\n",
    "#print(weekly)\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(weekly.index, weekly, color='tab:blue', marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
